# Dev_Incept_NLP
<h2>TOPICS COVERED IN THIS PROGRAM:</h2>

<h3>Pre-requisite :Git Introduction and Git Markdown</h3>
<h5>......................................................<h5>
<h3>Week1:Git Introduction and Git Markdown</h3>
<h4>Part1: Numpy basics <br>
Part1: Numpy notebook <br>
Part2: Pandas basics <br>
Part2: Pandas notebook <br>
Part3: Regular Expression basics <br>
Part3: Regular Expression notebook<br>
Part4: Competition-Numpy&Pandas<br>
Part5: Introduction to NLP<br>
Part6: Introduction to NLTK<br>
Part7: Basic functions in NLTK<br>
Tokenization<br>
Stemming<br>
ParsingBasic_functions_in_NLTK.md<br>
Lemmatization<br>
POS tagging<br>
Chunking<br>
Part7: Project:Basic functions in NLTK<br>
Part8: Mini Project: Text preprocessing using NLP<br>
</h4>
<h5>......................................................<h5>
<h3>Week2</h3>
<h4> Part1: Bag Of Words<br>
Part1: BOW Notebook<br>
Part2: Term Frequency-Inverse Document Frequency<br>
Part2: TF-IDF Notebook<br>
Part3: Sklearn<br>
Splitting train and test dataset<br>
Model selection<br>
Training and prediction<br>
Accuracy(Confusion matrix)<br>
Part3: Sklearn Notebook<br>
Part4: Project:Sentiment Analysis<br>
Part4: Project:Sentiment Analysis Notebook<br>
Part5: Project:Sentiment Analysis using Naive Bayes<br>
Part5: Project:Sentiment Analysis Notebook using Naive Bayes<br>
Part5: Competition-Checking Accuracy for different models<br>
part6: Bonus: Bert</h4>
<h5>......................................................<h5>
<h3>Week3</h3>
<h4>
Part1: Introduction to Pytorch<br>
Overview<br>
Loading the data<br>
Creating the model class<br>
Instantiating the model<br>
Training<br>
Evaluation<br>
Part1: Pytorch notebook<br>
Part2: Word Embeddings<br>
Part3: Word2Vec model<br>
CBOW(Continous bag of words)<br>
Skip-Gram<br>
Part4: Word2Vec notebook<br>
Part5: Subsampling<br>
Part5: Subsampling Notebook<br>
Part6: Adding up all for Skip-Gram Model<br>
Part7: Assignment  <br>
</h4>
<h5>......................................................<h5>
<h3>Week4</h3>
  <h4>
    Part1: Skip-Gram Model<br>
Part1: Skip-Gram Model Notebook<br>
Part2 Assignment: Study T-SNE for visualization<br>
Part3: Project: Finding Similar words in the text<br>
Part3: Project: Finding Similar words in the text Notebook<br>
Part4: Project: Generating tv scripts<br>
Part4: Project: Generating tv scripts Notebook<br>
  </h4>
 <h5>......................................................<h5>
